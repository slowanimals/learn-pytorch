{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/tIg+meCv60+OSvNKXKxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slowanimals/learn-pytorch/blob/main/01_pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. Pytorch Workflows"
      ],
      "metadata": {
        "id": "NhBWYW54NeeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Pytorch end-to-end workflow"
      ],
      "metadata": {
        "id": "AvzV8okSuJgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn  # pytorch's neural network tools\n",
        "import matplotlib.pyplot as plt  # for visualization\n",
        "import numpy as np\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "P5FblPhPuL3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression\n",
        "Using a Linear Regression formula to make a straight line with known parameters\n",
        "\n",
        "**y = mx + b**"
      ],
      "metadata": {
        "id": "uykDd0xWHfQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create known parameters\n",
        "weight = 0.7  # m\n",
        "bias = 0.3  # b\n",
        "\n",
        "# Create data\n",
        "X = torch.arange(0.,1.,0.02).unsqueeze(dim=1)  # unsqueeze turns X into a 2D vector of size [50,1]\n",
        "y = (weight * X) + bias  # y will be the labels\n",
        "\n",
        "print(X[:10])\n",
        "print(y[:10])"
      ],
      "metadata": {
        "id": "1BTGUq-T92SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X), len(y))"
      ],
      "metadata": {
        "id": "LZ72vr5CJg0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Creating & Splitting Data"
      ],
      "metadata": {
        "id": "x8mb7lYcPdI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(X))  # 80%, or 40 samples\n",
        "X_train = X[:train_split]\n",
        "y_train = y[:train_split]\n",
        "\n",
        "X_test = X[train_split:]  # 20%, or 10 samples\n",
        "y_test = y[train_split:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "id": "n4lcBXBoJw5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize!\n",
        "\n",
        "1. We will train the model with the training datasets.\n",
        "2. Then we will apply it to the test data to make predictions, and compare the model's predictions with the test labels' values."
      ],
      "metadata": {
        "id": "-0nHa2QsQjIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting training data, test data, & predictions\n",
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = None):\n",
        "  plt.figure(figsize=(7,5))\n",
        "\n",
        "  # blue training data scatterplot\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training Data\")\n",
        "\n",
        "  # green testing data scatterplot\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing Data\")\n",
        "\n",
        "  # are there predictions?\n",
        "  if predictions is not None:\n",
        "    plt.scatter(test_data, predictions, c='r', s=4, label = \"Predictions\")\n",
        "\n",
        "  # show the legend\n",
        "  plt.legend(prop={\"size\":14})"
      ],
      "metadata": {
        "id": "lQxQQpuwQmuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "id": "PO5xf_zqUfl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building a Linear Regression Model\n"
      ],
      "metadata": {
        "id": "ln_4acEFmJ_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The way this model works is:\n",
        "1. Creates random numbers representing the weight and bias\n",
        "2. Look at the training samples\n",
        "3. Runs the weight and bias through the forward function to adjust them to better represent the pattern found in the training samples\n",
        "\n",
        "**How does it do so?**\n",
        "Gradient descent & Backpropagation (which is why we do `requires_grad=True`)"
      ],
      "metadata": {
        "id": "l6NTRoTaq0mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(1,  # start with 1 random tensor that will be adjusted\n",
        "                                            requires_grad=True,  # parameter can be updated with gradient descent\n",
        "                                            dtype=torch.float))  # requires_grad is default true & float == float32\n",
        "\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                         requires_grad=True,\n",
        "                                         dtype=torch.float))\n",
        "\n",
        "    # forward method for defining the computation in the model\n",
        "  def forward(self, x:torch.Tensor) -> torch.Tensor:  # x (input) has to be type torch.Tensor and returns type torch.Tensor\n",
        "      return (self.weight * x) + self.bias  # y = mx + b"
      ],
      "metadata": {
        "id": "XyIybpSomNyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Contents of Our Model"
      ],
      "metadata": {
        "id": "7K9rIx2N46yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create manual seed in order to have reproducible results\n",
        "seed = torch.manual_seed(5)\n",
        "\n",
        "# create instance of model (subclass of nn.Module)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# check our parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "Qy637d_c4wfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "RgAhyQ8x6XTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions via `torch.inference_mode()`\n",
        "Let's see how well our model predicts y_test based on X_test.  \n",
        "When we pass data through the model, it will be run through the `forward()` method.\n"
      ],
      "metadata": {
        "id": "ZQUG9AzHl8-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:10], y_test[:10]"
      ],
      "metadata": {
        "id": "VcbzrjOxmxrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_predict = model_0(X_test)\n",
        "y_predict"
      ],
      "metadata": {
        "id": "b-WXqzDR6ucA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_predict)"
      ],
      "metadata": {
        "id": "k5M3Zzu-mtuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the parameters are randomly initialized, the predictions are completely random"
      ],
      "metadata": {
        "id": "rFHZJ6h6uS_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-initiating model for convenience\n",
        "torch.manual_seed(5)\n",
        "model_0 = LinearRegressionModel()\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "KSL5A7KlhFqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train Model\n",
        "The idea is to move from poor representation of data to a better one   \n",
        "We're going to use a Loss Function to achieve this goal"
      ],
      "metadata": {
        "id": "6Qg83ICFusRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# set up an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                            lr=0.01)"
      ],
      "metadata": {
        "id": "CknG0-VRn_TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Training & Testing Loops"
      ],
      "metadata": {
        "id": "LeTkL8tqIa-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000 # an epoch is 1 loop through the data (hyperparameter since we set it ourselves)\n",
        "\n",
        "# track values\n",
        "epoch_count = []\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "weight_values = []\n",
        "bias_values = []\n",
        "\n",
        "for epoch in range(epochs):  # pass data through a number of epochs\n",
        "\n",
        "  # Set model to training mode\n",
        "  model_0.train()  # training mode in Pytorch makes requires_grad = True\n",
        "\n",
        "  # 1. Forward pass that calls forward() method\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)  # order is prediction, target\n",
        "  #print(f'Loss: {loss}')\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on loss with respect to parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step (Gradient Descent)\n",
        "  optimizer.step()  # by default, how the optimizer changes will accumulate through the loop\n",
        "\n",
        "\n",
        "  ## TESTING\n",
        "  model_0.eval()  # turns off unneeded settings\n",
        "  with torch.inference_mode():  # turns off gradient tracking and other stuff\n",
        "    # 1. Forward pass\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out what's happening\n",
        "  if epoch % 100 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    train_loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "\n",
        "    weight_values.append(model_0.state_dict()['weight'].item())\n",
        "    bias_values.append(model_0.state_dict()['bias'].item())\n",
        "\n",
        "    print(f'Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}')\n",
        "    #print(model_0.state_dict()['weight'].item(), model_0.state_dict()['bias'].item())\n",
        "    print(model_0.state_dict())\n",
        ""
      ],
      "metadata": {
        "id": "bLLOgocQKfa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred_new = model_0(X_test)\n",
        "  plot_predictions(predictions = y_pred_new)"
      ],
      "metadata": {
        "id": "YcrD5g50XhHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Loss Curves"
      ],
      "metadata": {
        "id": "X7ctvArK1PIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count"
      ],
      "metadata": {
        "id": "6Mc2SXBX1QdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_values"
      ],
      "metadata": {
        "id": "OVX1QLgY1Zc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loss_values needs to be converted into a tensor and then into a numpy array\n",
        "np.array(torch.tensor(test_loss_values).numpy())"
      ],
      "metadata": {
        "id": "V-DICcbB1kBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_count,\n",
        "         torch.tensor(train_loss_values).detach().numpy(),\n",
        "         label=\"Train Loss\")\n",
        "plt.plot(epoch_count,\n",
        "         torch.tensor(test_loss_values).detach().numpy(),\n",
        "         label=\"Test Loss\")\n",
        "plt.ylabel(\"Train Loss\")\n",
        "plt.xlabel(\"Test Loss\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "c72YZLo71lk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_count,\n",
        "    torch.tensor(weight_values).numpy(),\n",
        "    label=\"Weight\")\n",
        "plt.plot(epoch_count,\n",
        "         torch.tensor(bias_values).numpy(),\n",
        "         label=\"Bias\")\n",
        "plt.xlabel(\"Weight\")\n",
        "plt.ylabel(\"Bias\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "XvTaYc2820ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Saving a Model"
      ],
      "metadata": {
        "id": "s8-j1MsS7Yvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create model's directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = '01_model_0.pt'  # convention is to save pytorch models as .pt or .pth\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save model's state dict\n",
        "torch.save(obj = model_0.state_dict(), f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "G0VxZohUVXdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "id": "BzHMVWYBWMdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a Model"
      ],
      "metadata": {
        "id": "i8NanVkfXTU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we only saved the state dict, we create a new instance of the model\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# load the saved state dict of model_0\n",
        "loaded_model_0.load_state_dict(torch.load(f = MODEL_SAVE_PATH))\n",
        "\n",
        "model_0.state_dict() == loaded_model_0.state_dict()"
      ],
      "metadata": {
        "id": "AH38MUK_XVIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting It All Together"
      ],
      "metadata": {
        "id": "9GFz3FlOb2Ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "hz9VdosCcIGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "bdWL1hFmb6Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write Device Agnostic Code"
      ],
      "metadata": {
        "id": "-uNQw9wZk-Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'using device: {device}')"
      ],
      "metadata": {
        "id": "D2_rIrxQlBH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Data"
      ],
      "metadata": {
        "id": "MMlTCo0ccMK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.3\n",
        "bias = 0.5\n",
        "\n",
        "data = torch.arange(0,1,0.02).unsqueeze(dim=1)\n",
        "labels = (data * weight) + bias\n",
        "\n",
        "train_split = int(0.8 * len(data))\n",
        "\n",
        "train_data = data[:train_split]\n",
        "train_labels = labels[:train_split]\n",
        "\n",
        "test_data = data[train_split:]\n",
        "test_labels = labels[train_split:]"
      ],
      "metadata": {
        "id": "Aydq0P-QcOKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model"
      ],
      "metadata": {
        "id": "RAjGI8G1ciUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # create linear layers\n",
        "    self.linearLayer = nn.Linear(in_features = 1,\n",
        "                                 out_features = 1)  # input and output of size 1\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linearLayer(x)\n",
        "\n",
        "torch.manual_seed(5)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "Z_mWhoQudKS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Model to Use Target Device"
      ],
      "metadata": {
        "id": "i115dhy7piLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "400qtVGPpk-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "E8F40gKipxK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Visualization Function"
      ],
      "metadata": {
        "id": "pBsaZGxYd0Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data = train_data,\n",
        "                     test_data = test_data,\n",
        "                     train_labels = train_labels,\n",
        "                     test_labels = test_labels,\n",
        "                     predictions = None):\n",
        "  plt.figure(figsize=(8,5))\n",
        "\n",
        "  plt.scatter(train_data, train_labels, s=4, c='b', label = \"Training Data\")\n",
        "\n",
        "  plt.scatter(test_data, test_labels, s=4, c='g', label = \"Testing Data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    plt.scatter(test_data, predictions, s=4, c='r', label = \"Predictions\")\n",
        "\n",
        "  plt.legend(prop={\"size\":14});"
      ],
      "metadata": {
        "id": "A5ih8wPTd1du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training/Eval Loop with L1Loss and SGD"
      ],
      "metadata": {
        "id": "BiIWfZ0CgqzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = LinearRegressionModelV2()\n",
        "model_1.to(device)\n",
        "list(model_1.parameters())"
      ],
      "metadata": {
        "id": "7bg_DhCLjE8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(params = model_1.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "wrDGeC0LguZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(5)\n",
        "\n",
        "epochs = 1000\n",
        "\n",
        "# put data on same bias to keep device agnostic code\n",
        "train_data = train_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "train_labels = train_labels.to(device)\n",
        "test_labels = test_labels.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # TRAINING\n",
        "  model_1.train()\n",
        "\n",
        "  # forward pass\n",
        "  model_1_predict = model_1(train_data)\n",
        "\n",
        "  # calculate loss\n",
        "  loss = loss_fn(model_1_predict, train_labels)\n",
        "\n",
        "  # optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "\n",
        "  # optimizer gradient descent\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "  # TESTING\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(test_data)\n",
        "\n",
        "    test_loss = loss_fn(test_pred, test_labels)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}')\n",
        "      print(model_1.state_dict())"
      ],
      "metadata": {
        "id": "-S1xd-lHg-WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  plot_predictions(predictions = test_pred.cpu())  # matplotlib requires test_pred to be moved to the cpu"
      ],
      "metadata": {
        "id": "4VCx0zXpiTAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and Load model_1"
      ],
      "metadata": {
        "id": "hRfmGoa_uJZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "MqTecCG0DVau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_SAVE_PATH = MODEL_PATH / \"01_model_1.pt\"\n",
        "torch.save(obj = model_1.state_dict(), f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "4RFeG7AFuNFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new instance\n",
        "loaded_model_1 = LinearRegressionModelV2()\n",
        "\n",
        "loaded_model_1.load_state_dict(torch.load(f = MODEL_SAVE_PATH))\n",
        "\n",
        "# move loaded model to device\n",
        "loaded_model_1.to(device)"
      ],
      "metadata": {
        "id": "VosYynmwBo3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(loaded_model_1.parameters()).device"
      ],
      "metadata": {
        "id": "drKu8GwlCDJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Loaded Model"
      ],
      "metadata": {
        "id": "FIKboIfcEjcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_1_preds = loaded_model_1(test_data)\n",
        "\n",
        "test_pred == loaded_model_1_preds  # compare model 1 test predictions with loaded"
      ],
      "metadata": {
        "id": "iujfL_PQElSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}